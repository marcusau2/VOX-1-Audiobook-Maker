VRAM ALLOCATION FIX - RTX 4090 Stalling Issue
==============================================
Date: 2026-01-26

PROBLEM FIXED
-------------
RTX 4090 (and other high-end GPUs) were stalling during audiobook generation at batch size 5.
- Symptom: Only 2.06GB VRAM allocated (shown in app)
- Task Manager: 15GB VRAM reserved but not being used
- Result: Generation stalls, poor performance

ROOT CAUSE
----------
PyTorch's default CUDA memory allocator was being too conservative:
1. cuDNN benchmarking was disabled (limiting performance)
2. Memory allocator not configured for variable batch workloads
3. No memory warmup causing lazy allocation
4. Per-process memory fraction not set for high-VRAM GPUs

SOLUTION IMPLEMENTED
--------------------
1. Re-enabled cuDNN benchmarking for consistent batch sizes
2. Configured PYTORCH_CUDA_ALLOC_CONF with expandable_segments
3. Set per-process memory fraction based on GPU tier:
   - 24GB+ GPUs (4090): 95% VRAM limit
   - 12-16GB GPUs: 90% VRAM limit
   - <12GB GPUs: 85% VRAM limit
4. Added GPU warmup step before batch processing
5. Disabled deterministic mode for better performance

FILES CHANGED
-------------
backend.py (lines 231-260):
  - Added aggressive CUDA memory configuration
  - Configured allocator with expandable_segments
  - Set per-process memory fraction

backend.py (lines 549-575):
  - Added GPU warmup before rendering starts
  - Pre-allocates memory pools for batch processing

EXPECTED RESULTS
----------------
- VRAM allocation should match reserved memory (Task Manager)
- No more stalling during generation
- Better utilization of high-end GPU memory
- Faster batch processing

TESTING
-------
Test on RTX 4090 with batch size 5:
1. Watch Activity Log for "GPU warmup complete"
2. Check VRAM allocation after warmup (should be higher than 2GB)
3. Monitor during first batch (should allocate more memory)
4. Verify generation completes without stalling

HOW TO REVERT IF ISSUES OCCUR
------------------------------
If these changes cause problems, revert to the previous version:

METHOD 1: Using the backup branch
  git checkout backup-before-vram-fix

METHOD 2: Revert the specific commit
  git revert 02b6eae

METHOD 3: Hard reset to previous state
  git reset --hard backup-before-vram-fix

After reverting, the old conservative settings will be restored:
- cuDNN benchmark disabled
- No memory fraction limits
- No GPU warmup
- Conservative allocation behavior

WHAT TO REPORT
---------------
If you test this fix, please report:
1. GPU model and VRAM amount
2. Batch size tested
3. VRAM allocation after warmup (from Activity Log)
4. Whether generation completes without stalling
5. Any error messages or issues encountered

TECHNICAL DETAILS
-----------------
PyTorch CUDA Allocator Configuration:
- expandable_segments:True
  Allows memory segments to grow dynamically instead of fixed blocks

- max_split_size_mb:512
  Prevents excessive memory fragmentation by limiting split sizes

- set_per_process_memory_fraction(0.95)
  Tells PyTorch it can use up to 95% of GPU memory
  This is critical - without it, PyTorch defaults to ~50-60%

cuDNN Benchmark:
- Enabled for consistent batch sizes
- Finds optimal convolution algorithms
- Improves inference speed by 10-20%

Warmup Step:
- Generates a tiny sample before real batches
- Forces PyTorch to allocate memory pools upfront
- Prevents lazy allocation issues during first batch
- Synchronizes GPU to ensure allocation completes

COMMIT INFO
-----------
Commit: 02b6eae
Branch: main
Backup: backup-before-vram-fix

Author: Claude Sonnet 4.5
Date: 2026-01-26
